# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nIS1416Xn9hadz4iLz1RVwbHL7FnjSCG
"""

import torch
import tqdm
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
import cv2
import torchvision
from torchvision import datasets, models, transforms
from torchvision.transforms import v2
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import time
import os
import PIL
from PIL import Image
cudnn.benchmark = True

device = (
    "cuda"
    if torch.cuda.is_available()
    else "mps"
    if torch.backends.mps.is_available()
    else "cpu"
)
print(f"Using {device} device")

BASE_DIR = "/content/drive/MyDrive/Alzheimer MRI Disease Classification Dataset/Data"
disease_label_from_category = {
    0: "Mild Demented",
    1: "Moderate Demented",
    2: "Non Demented",
    3: "Very Mild Demented",
}

df = pd.read_parquet(f"{BASE_DIR}/train-00000-of-00001-c08a401c53fe5312.parquet", engine="pyarrow")
df.head()

test = pd.read_parquet(f"{BASE_DIR}/test-00000-of-00001-44110b9df98c5585.parquet", engine="pyarrow")

def dict_to_image(image_dict):
    if isinstance(image_dict, dict) and 'bytes' in image_dict:
        byte_string = image_dict['bytes']
        nparr = np.frombuffer(byte_string, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)
        return img
    else:
        raise TypeError(f"Expected dictionary with 'bytes' key, got {type(image_dict)}")

df['img_arr'] = df['image'].apply(dict_to_image)
df.drop("image", axis=1, inplace=True)
df.head()

test['img_arr'] = test['image'].apply(dict_to_image)
test.drop("image", axis=1, inplace=True)

fig, ax = plt.subplots(2, 3, figsize=(15, 5))
axs = ax.flatten()
for axes in axs:
    rand = np.random.randint(0, len(df))
    axes.imshow(df.iloc[rand]['img_arr'], cmap="gray")
    axes.set_title(disease_label_from_category[df.iloc[rand]['label']])
plt.tight_layout()
plt.show()

plt.figure(figsize=(9, 5))
plt.bar(np.arange(0, 4, 1), df['label'].value_counts().sort_index())
plt.ylabel("Number of Images")
plt.xticks(np.arange(0, 4, 1), labels=[disease_label_from_category[i] for i in range(4)])
plt.show()
print(f"Total samples in training data = {len(df)}")

N_CLASSES = df['label'].nunique()

class ImageDataset(Dataset):
    def __init__(self, dataframe):
        self.dataframe = dataframe

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        image = self.dataframe.iloc[idx]["img_arr"] # Get the label from the df
        label = self.dataframe.iloc[idx]["label"] # Get the img numpy array from the df
        # The CNN requires we add a channel dimension i.e. (128, 128) -> (1, 128, 128)
        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)
        label = torch.tensor(label, dtype=torch.long)
        return image, label

class BaselineCNN(nn.Module):
    # Basic CNN using 2D convolutional layers, some max pooling and
    # a single batch normalisation layer to counter overfitting. We used a linear (dense)
    # layer as the output with the output shape being the number of classes
    def __init__(self):
        super(BaselineCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.batchnorm1 = nn.BatchNorm2d(num_features=32)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(64 * 32 * 32, 128)
        self.out = nn.Linear(128, N_CLASSES)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(x)
        x = self.batchnorm1(x)
        x = F.relu(self.conv2(x))
        x = self.pool2(x)
        x = self.flatten(x)
        x = F.relu(self.fc1(x))
        x = self.out(x)
        return x

learning_rate = 0.001
NEPOCHS = 75
batch_size = 32

train_dataset = ImageDataset(df)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

def train_model(model, loader, optimizer, num_epochs=NEPOCHS):
    # Initialize model, loss function, and optimizer
    criterion = nn.CrossEntropyLoss()

    # Training loop
    train_losses = []
    for epoch in tqdm.tqdm(range(num_epochs), total=num_epochs):
        running_loss = 0.0
        for i, data in enumerate(loader, 0):
            inputs, labels = data[0].to(device), data[1].to(device)
            # zero the parameter gradients
            optimizer.zero_grad()
            # forward + backward + optimize
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()
        epoch_loss = running_loss / len(loader)
        train_losses.append(epoch_loss)

    print('Finished Training')
    return model, train_losses

model = BaselineCNN().to(device)
optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
model, train_losses = train_model(model, train_loader, optimizer)

plt.plot(np.arange(1, 11), train_losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

def predict(m, dl, device):
    m.eval()  # Set model to evaluation mode
    predictions = []
    true_labels = []

    with torch.no_grad():  # Disable gradient computation for inference
        for images, labels in dl:
            images = images.to(device)
            outputs = m(images)
            _, preds = torch.max(outputs, 1)  # Get the index of the max log-probability
            predictions.extend(preds.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())

    return predictions, true_labels

def result_summary(predictions, true_labels):
    # Accuracy
    accuracy = accuracy_score(true_labels, predictions)
    print(f'Accuracy: {accuracy:.4f}')

    # Confusion Matrix
    conf_matrix = confusion_matrix(true_labels, predictions)
    print('Confusion Matrix:')
    print(conf_matrix)

predictions, true_labels = predict(model, train_loader, device)
result_summary(predictions, true_labels)

test_dataset = ImageDataset(test)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
predictions_test, test_labels = predict(model, test_loader, device)

result_summary(predictions_test, test_labels)









"""**Inception**"""

def dict_to_image(image_dict):
    if isinstance(image_dict, dict) and 'bytes' in image_dict:
        byte_string = image_dict['bytes']
        nparr = np.frombuffer(byte_string, np.uint8)
        # Decode the image as grayscale
        img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)
        # Convert to PIL Image and then to 3 channels
        img = Image.fromarray(img).convert('RGB')
        return img
    else:
        raise TypeError(f"Expected dictionary with 'bytes' key, got {type(image_dict)}")

class ImageDataset(Dataset):
       def __init__(self, dataframe, transform):
           self.dataframe = dataframe
           self.transform = transform

       def __len__(self):
           return len(self.dataframe)

       def __getitem__(self, idx):
           # Get the image as a dictionary from the dataframe
           # CHANGED LINE BELOW: Access 'img_arr' instead of 'image'
           image = self.dataframe.iloc[idx]["img_arr"]
           # Convert the image dictionary to a PIL Image
           # CHANGED LINE BELOW: Convert NumPy array to PIL Image
           image = Image.fromarray(image).convert('RGB')
           label = self.dataframe.iloc[idx]["label"]

           if self.transform:
               # Apply transformations to the PIL Image
               image = self.transform(image)

           label = torch.tensor(label, dtype=torch.long)
           # No need to convert to tensor here, transform already does that

           return image, label

learning_rate = 0.001
NEPOCHS = 50
batch_size = 32

train_transforms = transforms.Compose([
    transforms.Resize(299),
    transforms.CenterCrop(299),
    transforms.RandomHorizontalFlip(p=0.3),
    transforms.RandomVerticalFlip(p=0.3),
    transforms.GaussianBlur(kernel_size=3),
    transforms.RandomRotation(degrees=(-45, 45)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_dataset = ImageDataset(df, train_transforms) # Needed as we changed the defn of ImageDataset
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

def train_model(model, loader, optimizer, num_epochs=NEPOCHS):
    """
    Train the Inception v3 model and compute training losses.

    Args:
        model: The PyTorch model to train.
        loader: DataLoader for training data.
        optimizer: Optimizer for model training.
        num_epochs: Number of epochs to train (default: NEPOCHS).

    Returns:
        model: Trained model.
        train_losses: List of training losses per epoch.
    """
    # Initialize loss function
    criterion = nn.CrossEntropyLoss()

    # Track training loss
    train_losses = []

    # Training loop
    for epoch in tqdm.tqdm(range(num_epochs), total=num_epochs):
        model.train()
        running_loss = 0.0

        for i, data in enumerate(loader, 0):
            # Get inputs and labels
            inputs, labels = data[0].to(device), data[1].to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(inputs)

            # Handle InceptionOutputs
            main_output = outputs.logits  # Main output
            aux_output = outputs.aux_logits  # Auxiliary output (optional)

            # Compute main and auxiliary losses
            main_loss = criterion(main_output, labels)
            aux_loss = criterion(aux_output, labels) if aux_output is not None else 0

            # Combine losses (with weighting for auxiliary loss)
            loss = main_loss + 0.4 * aux_loss

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            # Accumulate running loss
            running_loss += loss.item()

        # Compute average loss for the epoch
        epoch_loss = running_loss / len(loader)
        train_losses.append(epoch_loss)

        print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}")

    print("Finished Training")
    return model, train_losses

model = models.inception_v3(pretrained=True)
num_classes = 4
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, num_classes)
model = model.to(device)

optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
model, train_losses = train_model(model, train_loader, optimizer)

plt.plot(np.arange(1, 51), train_losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

def predict(m, dl, device):
    m.eval()  # Set model to evaluation mode
    predictions = []
    true_labels = []

    with torch.no_grad():  # Disable gradient computation for inference
        for images, labels in dl:
            images = images.to(device)
            outputs = m(images)
            _, preds = torch.max(outputs, 1)  # Get the index of the max log-probability
            predictions.extend(preds.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())

    return predictions, true_labels

def result_summary(predictions, true_labels):
    # Accuracy
    accuracy = accuracy_score(true_labels, predictions)
    print(f'Accuracy: {accuracy:.4f}')

    # Confusion Matrix
    conf_matrix = confusion_matrix(true_labels, predictions)
    print('Confusion Matrix:')
    print(conf_matrix)

predictions, true_labels = predict(model, train_loader, device)
result_summary(predictions, true_labels)

# Define a transform for the test set (e.g., basic preprocessing)
test_transforms = transforms.Compose([
    transforms.Resize(299),
    transforms.CenterCrop(299),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Pass the transform when creating the test dataset
test_dataset = ImageDataset(test, test_transforms)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
predictions_test, test_labels = predict(model, test_loader, device)

result_summary(predictions_test, test_labels)





"""**ResNet**"""

import torch
import tqdm
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
import cv2
import torchvision
from torchvision import datasets, models, transforms
from torchvision.transforms import v2
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import time
import os
import PIL
from PIL import Image
cudnn.benchmark = True

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import models, transforms
from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm

device = (
    "cuda"
    if torch.cuda.is_available()
    else "mps"
    if torch.backends.mps.is_available()
    else "cpu"
)
print(f"Using {device} device")

BASE_DIR = "/content/drive/MyDrive/Alzheimer MRI Disease Classification Dataset/Data"
disease_label_from_category = {
    0: "Mild Demented",
    1: "Moderate Demented",
    2: "Non Demented",
    3: "Very Mild Demented",
}

df = pd.read_parquet(f"{BASE_DIR}/train-00000-of-00001-c08a401c53fe5312.parquet", engine="pyarrow")
df.head()

test = pd.read_parquet(f"{BASE_DIR}/test-00000-of-00001-44110b9df98c5585.parquet", engine="pyarrow")

def dict_to_image(image_dict):
    if isinstance(image_dict, dict) and 'bytes' in image_dict:
        byte_string = image_dict['bytes']
        nparr = np.frombuffer(byte_string, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)
        return img
    else:
        raise TypeError(f"Expected dictionary with 'bytes' key, got {type(image_dict)}")

df['img_arr'] = df['image'].apply(dict_to_image)
df.drop("image", axis=1, inplace=True)
df.head()

test['img_arr'] = test['image'].apply(dict_to_image)
test.drop("image", axis=1, inplace=True)

fig, ax = plt.subplots(3, 2, figsize=(15, 5))
axs = ax.flatten()
for axes in axs:
    rand = np.random.randint(0, len(df))
    axes.imshow(df.iloc[rand]['img_arr'], cmap="gray")
    axes.set_title(disease_label_from_category[df.iloc[rand]['label']])
plt.tight_layout()
plt.show()

N_CLASSES = df['label'].nunique()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.CenterCrop(224),
    transforms.RandomHorizontalFlip(p=0.3),
    transforms.RandomVerticalFlip(p=0.3),
    transforms.GaussianBlur(kernel_size=3),
    transforms.RandomRotation(degrees=(-45, 45)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

class ImageDataset(Dataset):
       def __init__(self, dataframe, transform):
           self.dataframe = dataframe
           self.transform = transform

       def __len__(self):
           return len(self.dataframe)

       def __getitem__(self, idx):
           # Get the image as a dictionary from the dataframe
           image = self.dataframe.iloc[idx]["img_arr"]
           # Convert the image dictionary to a PIL Image
           image = Image.fromarray(image).convert('RGB')
           label = self.dataframe.iloc[idx]["label"]

           if self.transform:
               # Apply transformations to the PIL Image
               image = self.transform(image)

           label = torch.tensor(label, dtype=torch.long)
           # No need to convert to tensor here, transform already does that

           return image, label

learning_rate = 0.001
NEPOCHS = 50
batch_size = 32


train_dataset = ImageDataset(df, transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

test_dataset = ImageDataset(test, transform)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# def train_and_evaluate_model_with_early_stopping(model, train_loader, test_loader, optimizer, num_epochs=5, patience=5, device="cuda"):
def train_and_evaluate_model_with_early_stopping(model, train_loader, test_loader, optimizer, num_epochs=50,  device="cuda"):
    criterion = nn.CrossEntropyLoss()
    model.to(device)

    train_losses, test_losses = [], []
    train_accuracies, test_accuracies = [], []

    best_test_loss = float('inf')
    patience_counter = 0

    all_labels, all_preds = [], []  # To store all test labels and predictions

    for epoch in tqdm(range(num_epochs), desc="Training Progress"):
        # Training
        model.train()
        running_loss, correct, total = 0.0, 0, 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, preds = outputs.max(1)
            correct += preds.eq(labels).sum().item()
            total += labels.size(0)

        train_losses.append(running_loss / len(train_loader))
        train_accuracies.append(100.0 * correct / total)

        # Testing
        model.eval()
        running_loss, correct, total = 0.0, 0, 0
        epoch_labels, epoch_preds = [], []
        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)

                loss = criterion(outputs, labels)
                running_loss += loss.item()

                _, preds = outputs.max(1)
                correct += preds.eq(labels).sum().item()
                total += labels.size(0)

                epoch_labels.extend(labels.cpu().numpy())
                epoch_preds.extend(preds.cpu().numpy())

        test_loss = running_loss / len(test_loader)
        test_losses.append(test_loss)
        test_accuracies.append(100.0 * correct / total)

        # Update all labels and predictions
        all_labels = epoch_labels
        all_preds = epoch_preds

        # Early stopping logic
        # if test_loss < best_test_loss:
        #     best_test_loss = test_loss
        #     patience_counter = 0
        # else:
        #     patience_counter += 1

        # if patience_counter >= patience:
        #     print(f"Early stopping triggered at epoch {epoch + 1}")
        #     break

    return train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds

def visualize_predictions(model, test_loader, device="cuda"):
    model.eval()
    images, labels = next(iter(test_loader))
    images, labels = images[:6].to(device), labels[:6].to(device)  # Get 6 samples

    with torch.no_grad():
        outputs = model(images)
        _, preds = outputs.max(1)

    images = images.cpu().numpy()

    fig, axes = plt.subplots(3, 2, figsize=(15, 5))
    #fig.suptitle('Test Images and Predictions', fontsize=16) # Add a centered title
    axes = axes.flatten()
    for idx in range(6):
        image = images[idx].transpose((1, 2, 0))
        label = labels[idx].item()
        pred = preds[idx].item()

        # CHANGED LINE BELOW: Use plt.imshow instead of axes[idx].imshow
        plt.subplot(3, 2, idx+1) # Use plt.subplot for subplots
        plt.imshow((image - image.min()) / (image.max() - image.min()))
        plt.title(f"Label: {label}\nPred: {pred}")
        plt.axis("off")

    plt.tight_layout()
    plt.show()

def plot_metrics(train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds):
    epochs = range(1, len(train_losses) + 1)

    # Plot Loss
    plt.figure(figsize=(10, 5))
    plt.plot(epochs, train_losses, label="Training Loss")
    plt.plot(epochs, test_losses, label="Testing Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Training vs. Testing Loss")
    plt.legend()
    plt.show()

    # Plot Accuracy
    plt.figure(figsize=(10, 5))
    plt.plot(epochs, train_accuracies, label="Training Accuracy")
    plt.plot(epochs, test_accuracies, label="Testing Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy (%)")
    plt.title("Training vs. Testing Accuracy")
    plt.legend()
    plt.show()

    # Confusion Matrix
    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(all_labels))
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.show()

    # ROC Curve
    all_labels_one_hot = np.eye(len(np.unique(all_labels)))[all_labels]
    all_preds_probs = np.eye(len(np.unique(all_preds)))[all_preds]

    fpr, tpr, roc_auc = {}, {}, {}
    for i in range(len(np.unique(all_labels))):
        fpr[i], tpr[i], _ = roc_curve(all_labels_one_hot[:, i], all_preds_probs[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    plt.figure(figsize=(10, 5))
    for i in fpr:
        plt.plot(fpr[i], tpr[i], label=f"Class {i} (AUC = {roc_auc[i]:.2f})")
    plt.plot([0, 1], [0, 1], "k--", label="Random")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend()
    plt.show()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

"""#**ResNet 50**"""

model = models.resnet50(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 4)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds = train_and_evaluate_model_with_early_stopping(
    model, train_loader, test_loader, optimizer, num_epochs=50, device=device
)

plot_metrics(train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds)

visualize_predictions(model, test_loader, device)

accuracy_score(all_labels, all_preds)

from sklearn.metrics import precision_score, recall_score, f1_score
# Assuming 'all_labels' are the true labels and 'all_preds' are the predicted labels
precision = precision_score(all_labels, all_preds, average='weighted')
recall = recall_score(all_labels, all_preds, average='weighted')
f1 = f1_score(all_labels, all_preds, average='weighted')

print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

"""###**Early Stopping**"""

train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds = train_and_evaluate_model_with_early_stopping(
    model, train_loader, test_loader, optimizer, num_epochs=75, patience = 3, device=device
)

plot_metrics(train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds)

accuracy_score(all_labels, all_preds)

"""**ResNet 18**"""

model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 4)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds = train_and_evaluate_model(
    model, train_loader, test_loader, optimizer, num_epochs=50, device=device
)

plot_metrics(train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds)

accuracy_score(all_labels, all_preds)

from sklearn.metrics import recall_score, precision_score
recall_score(all_labels, all_preds, average=None)

precision_score(all_labels, all_preds, average=None)







"""**ResNet 34**"""

model = models.resnet34(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 4)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds = train_and_evaluate_model(
    model, train_loader, test_loader, optimizer, num_epochs=50, device=device
)

plot_metrics(train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds)

accuracy_score(all_labels, all_preds)



"""##**ResNet 101**"""

model = models.resnet101(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 4)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds = train_and_evaluate_model(
    model, train_loader, test_loader, optimizer, num_epochs=50, device=device
)

plot_metrics(train_losses, test_losses, train_accuracies, test_accuracies, all_labels, all_preds)

accuracy_score(all_labels, all_preds)

